{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install numpy scikit-learn wlplan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see how you can use `wlplan` for both training and search, see this [test](../../tests/train_eval_blocks_test.py). This notebook only contains the training part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pymimir\n",
    "import wlplan\n",
    "from wlplan.data import Dataset, ProblemStates\n",
    "from wlplan.feature_generation import WLFeatures\n",
    "from wlplan.planning import Predicate, parse_domain\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import DotProduct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Define the state space for the Blocksworld domain with first-order logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_to_predicate = {\n",
    "    \"on\": Predicate(\"on\", 2),\n",
    "    \"on-table\": Predicate(\"on-table\", 1),\n",
    "    \"clear\": Predicate(\"clear\", 1),\n",
    "    \"holding\": Predicate(\"holding\", 1),\n",
    "    \"arm-empty\": Predicate(\"arm-empty\", 0),\n",
    "}\n",
    "predicates = list(name_to_predicate.values())\n",
    "wlplan_domain = wlplan.planning.Domain(name=\"blocksworld\", predicates=predicates)\n",
    "# Alternatively, you can directly parse the domain from a PDDL file\n",
    "# wlplan_domain = parse_domain(\"blocksworld/domain.pddl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. [The most work] Parse training data in the form of (state, optimal cost to go) pairs using a parser of your choice. Here, I used `mimir` but anything else can do. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_pddl = \"blocksworld/domain.pddl\"\n",
    "mimir_domain = pymimir.DomainParser(str(domain_pddl)).parse()\n",
    "\n",
    "wlplan_data = []\n",
    "y = []\n",
    "\n",
    "for f in os.listdir(\"blocksworld/training_plans\"):\n",
    "    problem_pddl = \"blocksworld/training/\" + f.replace(\".plan\", \".pddl\")\n",
    "    plan_file = \"blocksworld/training_plans/\" + f\n",
    "\n",
    "    # Parse problem with mimir\n",
    "    mimir_problem = pymimir.ProblemParser(str(problem_pddl)).parse(mimir_domain)\n",
    "    mimir_state = mimir_problem.create_state(mimir_problem.initial)\n",
    "\n",
    "    name_to_schema = {s.name: s for s in mimir_domain.action_schemas}\n",
    "    name_to_object = {o.name: o for o in mimir_problem.objects}\n",
    "\n",
    "    # Construct wlplan problem\n",
    "    positive_goals = []\n",
    "    for literal in mimir_problem.goal:\n",
    "        assert not literal.negated\n",
    "        mimir_atom = literal.atom\n",
    "        wlplan_atom = wlplan.planning.Atom(\n",
    "            predicate=name_to_predicate[mimir_atom.predicate.name],\n",
    "            objects=[o.name for o in mimir_atom.terms],\n",
    "        )\n",
    "        positive_goals.append(wlplan_atom)\n",
    "\n",
    "    wlplan_problem = wlplan.planning.Problem(\n",
    "        domain=wlplan_domain,\n",
    "        objects=list(name_to_object.keys()),\n",
    "        positive_goals=positive_goals,\n",
    "        negative_goals=[],\n",
    "    )\n",
    "    # Alternatively, you can directly parse the domain from a PDDL file\n",
    "    # wlplan_problem = parse_problem(domain_pddl, problem_pddl)\n",
    "    \n",
    "    # Collect actions\n",
    "    actions = []\n",
    "    with open(plan_file, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            if line.startswith(\";\"):\n",
    "                continue\n",
    "            action_name = line.strip()\n",
    "            action_name = action_name.replace(\"(\", \"\")\n",
    "            action_name = action_name.replace(\")\", \"\")\n",
    "            toks = action_name.split(\" \")\n",
    "            schema = toks[0]\n",
    "            schema = name_to_schema[schema]\n",
    "            args = toks[1:]\n",
    "            args = [name_to_object[arg] for arg in args]\n",
    "            action = pymimir.Action.new(mimir_problem, schema, args)\n",
    "            actions.append(action)\n",
    "\n",
    "    # Collect plan trace states\n",
    "    wlplan_states = []\n",
    "\n",
    "    def mimir_to_wlplan_state(mimir_state: pymimir.State):\n",
    "        wlplan_state = []\n",
    "        for atom in mimir_state.get_atoms():\n",
    "            wlplan_atom = wlplan.planning.Atom(\n",
    "                predicate=name_to_predicate[atom.predicate.name],\n",
    "                objects=[o.name for o in atom.terms],\n",
    "            )\n",
    "            wlplan_state.append(wlplan_atom)\n",
    "        return wlplan_state\n",
    "    \n",
    "    h_opt = len(actions)\n",
    "    wlplan_states.append(mimir_to_wlplan_state(mimir_state))\n",
    "    y.append(h_opt)\n",
    "    for action in actions:\n",
    "        h_opt -= 1\n",
    "        mimir_state = action.apply(mimir_state)\n",
    "        wlplan_states.append(mimir_to_wlplan_state(mimir_state))\n",
    "        y.append(h_opt)\n",
    "\n",
    "    problem_states = ProblemStates(problem=wlplan_problem, states=wlplan_states)\n",
    "    wlplan_data.append(problem_states)\n",
    "\n",
    "# This is what we need to feed into our feature generator below\n",
    "dataset = Dataset(domain=wlplan_domain, data=wlplan_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Collect and generate features from the preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_generator = WLFeatures(domain=wlplan_domain, iterations=4)\n",
    "feature_generator.collect(dataset)\n",
    "X = np.array(feature_generator.embed(dataset)).astype(float)\n",
    "y = np.array(y)\n",
    "print(f\"{X.shape=}\")\n",
    "print(f\"{y.shape=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a Gaussian Process Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_kernel = DotProduct(sigma_0=0, sigma_0_bounds=\"fixed\")\n",
    "model = GaussianProcessRegressor(kernel=linear_kernel, alpha=1e-7, random_state=0)\n",
    "model.fit(X, y)\n",
    "y_pred = model.predict(X)\n",
    "loss = np.mean((y - y_pred) ** 2)\n",
    "print(f\"{loss=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wlplan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
